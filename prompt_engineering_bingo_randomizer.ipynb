{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa0474f",
   "metadata": {},
   "source": [
    "# Prompt Engineering Bingo Randomizer\n",
    "\n",
    "This notebook creates multiple randomized versions of a DOCX bingo sheet by shuffling table cell texts. The text content stays the same; only positions inside the table change. It also writes CSV summaries to inspect the randomized layouts.\n",
    "\n",
    "Place your original DOCX (e.g. \"Prompt Engineering Bingo.docx\") in the repository root. If not found, the notebook will use the included `test.docx`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ed569",
   "metadata": {},
   "source": [
    "## Setup: imports, configuration, and output directory\n",
    "\n",
    "- Configure input file, output directory, number of versions, and random seed.\n",
    "- The seed ensures reproducibility.\n",
    "- If your file is named differently, adjust `candidate_paths` or set `input_path` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b96d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T08:38:00.272879Z",
     "iopub.status.busy": "2025-08-29T08:38:00.272721Z",
     "iopub.status.idle": "2025-08-29T08:38:00.569877Z",
     "shell.execute_reply": "2025-08-29T08:38:00.569389Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Configure paths and parameters\n",
    "root = Path('.')\n",
    "candidate_paths = [\n",
    "    root / 'Prompt Engineering Bingo.docx',\n",
    "    root / 'Prompt.Engineering.Bingo.docx',\n",
    "    root / 'test.docx',\n",
    "]\n",
    "input_path = next((p for p in candidate_paths if p.exists()), None)\n",
    "if input_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No input DOCX found. Place 'Prompt Engineering Bingo.docx' in the repository root or use 'test.docx'.\"\n",
    "    )\n",
    "\n",
    "outdir = Path('randomized_bingo')\n",
    "outdir.mkdir(exist_ok=True)\n",
    "\n",
    "n_versions = 20  # number of randomized outputs\n",
    "seed = 42        # change this for different reproducible shuffles\n",
    "all_tables = False  # set True to randomize all tables; False = only largest table\n",
    "\n",
    "# Save a small config snapshot\n",
    "pd.DataFrame([\n",
    "    {\n",
    "        'input_path': str(input_path),\n",
    "        'outdir': str(outdir),\n",
    "        'n_versions': n_versions,\n",
    "        'seed': seed,\n",
    "        'all_tables': all_tables,\n",
    "    }\n",
    "]).to_csv(outdir / 'config.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7627583",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "- Extract texts from a table.\n",
    "- Assign texts back to a table.\n",
    "- Select the largest table in a document.\n",
    "- Enumerate (row, col) pairs for cells for CSV summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ade79d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T08:38:00.571892Z",
     "iopub.status.busy": "2025-08-29T08:38:00.571702Z",
     "iopub.status.idle": "2025-08-29T08:38:00.577058Z",
     "shell.execute_reply": "2025-08-29T08:38:00.576603Z"
    }
   },
   "outputs": [],
   "source": [
    "def table_cell_texts(table):\n",
    "    return [cell.text for row in table.rows for cell in row.cells]\n",
    "\n",
    "def assign_texts_to_table(table, texts):\n",
    "    cells = [cell for row in table.rows for cell in row.cells]\n",
    "    if len(cells) != len(texts):\n",
    "        raise ValueError(\n",
    "            f\"Number of texts ({len(texts)}) does not match number of cells ({len(cells)}).\"\n",
    "        )\n",
    "    for cell, txt in zip(cells, texts):\n",
    "        cell.text = txt or ''\n",
    "\n",
    "def index_of_largest_table(doc):\n",
    "    if not doc.tables:\n",
    "        return None\n",
    "    sizes = [sum(1 for _ in (c for r in t.rows for c in r.cells)) for t in doc.tables]\n",
    "    return max(range(len(sizes)), key=lambda i: sizes[i])\n",
    "\n",
    "def row_col_pairs(table):\n",
    "    pairs = []\n",
    "    for r_idx, row in enumerate(table.rows):\n",
    "        for c_idx, _cell in enumerate(row.cells):\n",
    "            pairs.append((r_idx, c_idx))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d073a1",
   "metadata": {},
   "source": [
    "## Inspect the input document and save a summary\n",
    "\n",
    "- Count tables and their sizes (number of cells).\n",
    "- Identify the largest table and save the original texts for reference.\n",
    "- Results are saved as CSV in the output directory for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd77a89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T08:38:00.578712Z",
     "iopub.status.busy": "2025-08-29T08:38:00.578543Z",
     "iopub.status.idle": "2025-08-29T08:38:00.748579Z",
     "shell.execute_reply": "2025-08-29T08:38:00.747696Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input document contains no tables to randomize.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(doc\u001b[38;5;241m.\u001b[39mtables)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_tables \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input document contains no tables to randomize.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m (c \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mrows \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mcells)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mtables]\n\u001b[1;32m      7\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_index\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_tables)),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_cells\u001b[39m\u001b[38;5;124m'\u001b[39m: sizes,\n\u001b[1;32m     10\u001b[0m })\n",
      "\u001b[0;31mValueError\u001b[0m: The input document contains no tables to randomize."
     ]
    }
   ],
   "source": [
    "doc = Document(str(input_path))\n",
    "n_tables = len(doc.tables)\n",
    "if n_tables == 0:\n",
    "    raise ValueError(\"The input document contains no tables to randomize.\")\n",
    "\n",
    "sizes = [sum(1 for _ in (c for r in t.rows for c in r.cells)) for t in doc.tables]\n",
    "summary_df = pd.DataFrame({\n",
    "    'table_index': list(range(n_tables)),\n",
    "    'n_cells': sizes,\n",
    "})\n",
    "summary_df.to_csv(outdir / 'tables_summary.csv', index=False)\n",
    "\n",
    "# Save original texts from the largest table for auditing\n",
    "largest_idx = index_of_largest_table(doc)\n",
    "largest_table = doc.tables[largest_idx]\n",
    "orig_pairs = row_col_pairs(largest_table)\n",
    "orig_texts = table_cell_texts(largest_table)\n",
    "orig_df = pd.DataFrame({\n",
    "    'row': [p[0] for p in orig_pairs],\n",
    "    'col': [p[1] for p in orig_pairs],\n",
    "    'text': orig_texts,\n",
    "})\n",
    "orig_df.to_csv(outdir / 'original_texts.csv', index=False)\n",
    "\n",
    "# Determine which table indices to randomize\n",
    "table_indices = list(range(n_tables)) if all_tables else [largest_idx]\n",
    "pd.DataFrame({'randomized_table_indices': table_indices}).to_csv(outdir / 'randomized_tables.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0baee",
   "metadata": {},
   "source": [
    "## Randomize and export multiple versions\n",
    "\n",
    "- For each version, shuffle the texts within the selected table(s).\n",
    "- Save each randomized DOCX to the output directory.\n",
    "- Save a CSV per version describing the shuffled layout (row, col, text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0369cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(seed)\n",
    "base = input_path.stem\n",
    "saved_files = []\n",
    "\n",
    "for i in range(1, n_versions + 1):\n",
    "    d = Document(str(input_path))\n",
    "    per_table_layouts = []\n",
    "    for idx in table_indices:\n",
    "        t = d.tables[idx]\n",
    "        texts = table_cell_texts(t)\n",
    "        shuffled = texts[:]\n",
    "        rng.shuffle(shuffled)\n",
    "        assign_texts_to_table(t, shuffled)\n",
    "\n",
    "        pairs = row_col_pairs(t)\n",
    "        layout_df = pd.DataFrame({\n",
    "            'version': i,\n",
    "            'table_index': idx,\n",
    "            'row': [p[0] for p in pairs],\n",
    "            'col': [p[1] for p in pairs],\n",
    "            'text': shuffled,\n",
    "        })\n",
    "        layout_df.to_csv(outdir / f'layout_{i:02d}_table_{idx}.csv', index=False)\n",
    "        per_table_layouts.append(layout_df)\n",
    "\n",
    "    out_path = outdir / f'{base}_randomized_{i:02d}.docx'\n",
    "    d.save(out_path)\n",
    "    saved_files.append(str(out_path))\n",
    "\n",
    "pd.DataFrame({'file': saved_files}).to_csv(outdir / 'randomized_files.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a21ca",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- To use a different input file, change `candidate_paths` or set `input_path` directly.\n",
    "- To randomize all tables, set `all_tables = True` in the setup cell.\n",
    "- To get different random layouts, change the `seed` value or set it to `None` for non-deterministic shuffles.\n",
    "- Outputs written:\n",
    "  - DOCX files in `randomized_bingo/`\n",
    "  - `tables_summary.csv` with table sizes\n",
    "  - `original_texts.csv` with the original texts of the largest table\n",
    "  - `randomized_tables.csv` showing which tables were randomized\n",
    "  - `layout_XX_table_T.csv` for each version/table with row/col/text\n",
    "  - `randomized_files.csv` listing all created DOCX files"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}