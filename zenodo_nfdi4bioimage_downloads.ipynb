{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dea0063",
   "metadata": {},
   "source": [
    "# Summarize downloads of the Zenodo community: nfdi4bioimage\n",
    "\n",
    "This notebook fetches all records from the Zenodo community `nfdi4bioimage`, extracts each record URL and its download count, and saves the result to a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c224e1",
   "metadata": {},
   "source": [
    "## Setup: imports and configuration\n",
    "\n",
    "We use only standard-library networking (urllib) to avoid extra dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ddfe2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T11:24:17.977621Z",
     "iopub.status.busy": "2025-11-20T11:24:17.977436Z",
     "iopub.status.idle": "2025-11-20T11:24:18.286787Z",
     "shell.execute_reply": "2025-11-20T11:24:18.286242Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "from urllib.parse import urlencode\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://zenodo.org/api/records\"\n",
    "COMMUNITY = \"nfdi4bioimage\"\n",
    "PAGE_SIZE = 200\n",
    "REQUEST_TIMEOUT = 30\n",
    "SLEEP_BETWEEN_PAGES = 0.2\n",
    "HEADERS = {\"User-Agent\": \"git-bob (github-actions bot)\", \"Accept\": \"application/json\"}\n",
    "RAW_JSON_PATH = \"zenodo_nfdi4bioimage_records.json\"\n",
    "CSV_PATH = \"zenodo_nfdi4bioimage_downloads.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394c12b",
   "metadata": {},
   "source": [
    "## Helper: small JSON GET utility\n",
    "\n",
    "Fetch a JSON response from a URL with headers and timeout. Returns `None` on error to keep the workflow robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424bf66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T11:24:18.288895Z",
     "iopub.status.busy": "2025-11-20T11:24:18.288632Z",
     "iopub.status.idle": "2025-11-20T11:24:18.292192Z",
     "shell.execute_reply": "2025-11-20T11:24:18.291708Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_json(url: str) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        req = Request(url, headers=HEADERS)\n",
    "        with urlopen(req, timeout=REQUEST_TIMEOUT) as resp:\n",
    "            data = resp.read().decode(\"utf-8\", errors=\"replace\")\n",
    "        return json.loads(data)\n",
    "    except (HTTPError, URLError, TimeoutError, json.JSONDecodeError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e05bd9",
   "metadata": {},
   "source": [
    "## Fetch all records via pagination\n",
    "\n",
    "We first try filtering by `communities` and follow `links.next`. If that returns no records, we fall back to a query-string search `q=communities:\"nfdi4bioimage\"` to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c7b956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T11:24:18.293861Z",
     "iopub.status.busy": "2025-11-20T11:24:18.293674Z",
     "iopub.status.idle": "2025-11-20T11:24:22.239712Z",
     "shell.execute_reply": "2025-11-20T11:24:22.239137Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_all_records() -> List[Dict[str, Any]]:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    def paginate(url: str) -> List[Dict[str, Any]]:\n",
    "        out: List[Dict[str, Any]] = []\n",
    "        seen_pages = 0\n",
    "        while url and seen_pages < 200:  # hard stop\n",
    "            data = get_json(url)\n",
    "            if not data:\n",
    "                break\n",
    "            hits = (data.get(\"hits\") or {}).get(\"hits\") or []\n",
    "            out.extend(hits)\n",
    "            next_link = (data.get(\"links\") or {}).get(\"next\")\n",
    "            url = next_link\n",
    "            seen_pages += 1\n",
    "            if url:\n",
    "                time.sleep(SLEEP_BETWEEN_PAGES)\n",
    "        return out\n",
    "\n",
    "    # Strategy 1: communities filter\n",
    "    params1 = {\n",
    "        \"communities\": COMMUNITY,\n",
    "        \"size\": PAGE_SIZE,\n",
    "        \"page\": 1,\n",
    "        \"all_versions\": 1,\n",
    "        \"sort\": \"mostrecent\",\n",
    "    }\n",
    "    url1 = f\"{BASE_URL}?{urlencode(params1)}\"\n",
    "    records = paginate(url1)\n",
    "\n",
    "    # Strategy 2: query fallback if needed\n",
    "    if not records:\n",
    "        params2 = {\n",
    "            \"q\": f\"communities:\\\"{COMMUNITY}\\\"\",\n",
    "            \"size\": PAGE_SIZE,\n",
    "            \"page\": 1,\n",
    "            \"all_versions\": 1,\n",
    "            \"sort\": \"mostrecent\",\n",
    "        }\n",
    "        url2 = f\"{BASE_URL}?{urlencode(params2)}\"\n",
    "        records = paginate(url2)\n",
    "\n",
    "    return records\n",
    "\n",
    "records = fetch_all_records()\n",
    "with open(RAW_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc394a",
   "metadata": {},
   "source": [
    "## Transform: extract Zenodo URL and downloads\n",
    "\n",
    "We extract the record page URL and total downloads (from `stats.downloads`). Missing values are treated as 0. We keep a few extra columns for context and sort by downloads (descending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246588a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T11:24:22.241563Z",
     "iopub.status.busy": "2025-11-20T11:24:22.241396Z",
     "iopub.status.idle": "2025-11-20T11:24:22.247277Z",
     "shell.execute_reply": "2025-11-20T11:24:22.246662Z"
    }
   },
   "outputs": [],
   "source": [
    "def rec_to_row(r: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    links = r.get(\"links\") or {}\n",
    "    rec_id = r.get(\"id\")\n",
    "    url = links.get(\"html\") or (f\"https://zenodo.org/records/{rec_id}\" if rec_id else None)\n",
    "    stats = r.get(\"stats\") or {}\n",
    "    downloads = stats.get(\"downloads\")\n",
    "    try:\n",
    "        downloads = int(downloads) if downloads is not None else 0\n",
    "    except Exception:\n",
    "        downloads = 0\n",
    "    md = r.get(\"metadata\") or {}\n",
    "    return {\n",
    "        \"zenodo_url\": url,\n",
    "        \"downloads\": downloads,\n",
    "        \"id\": rec_id,\n",
    "        \"doi\": r.get(\"doi\") or r.get(\"conceptdoi\"),\n",
    "        \"title\": md.get(\"title\"),\n",
    "    }\n",
    "\n",
    "rows = [rec_to_row(x) for x in records]\n",
    "df = pd.DataFrame(rows)\n",
    "if not df.empty:\n",
    "    df = df.dropna(subset=[\"zenodo_url\"]).drop_duplicates(subset=[\"zenodo_url\"])\\\n",
    "           .sort_values(\"downloads\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a1595",
   "metadata": {},
   "source": [
    "## Save the summary as CSV\n",
    "\n",
    "The CSV contains at least the Zenodo URL and the download count per record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a3b26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T11:24:22.248973Z",
     "iopub.status.busy": "2025-11-20T11:24:22.248690Z",
     "iopub.status.idle": "2025-11-20T11:24:22.253557Z",
     "shell.execute_reply": "2025-11-20T11:24:22.252984Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [\"zenodo_url\", \"downloads\", \"id\", \"doi\", \"title\"]\n",
    "(df[cols] if not df.empty else pd.DataFrame(columns=cols)).to_csv(CSV_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
