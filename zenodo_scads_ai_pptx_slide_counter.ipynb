{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6442b684",
   "metadata": {},
   "source": [
    "# Count slides in PPTX files from Zenodo community scads-ai\n",
    "This notebook:\n",
    "- Queries the Zenodo REST API for all records in the scads-ai community\n",
    "- Downloads all .pptx files\n",
    "- Counts slides using python-pptx\n",
    "- Saves per-file results to CSV and a short summary to JSON/TXT\n",
    "\n",
    "Tip: Set an environment variable `ZENODO_TOKEN` to a personal access token for higher rate limits and fewer failures. The notebook will work without a token, too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c76e6",
   "metadata": {},
   "source": [
    "Install required packages\n",
    "- We install all requirements at the beginning as requested.\n",
    "- If already installed, pip will be quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4040f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:34.609940Z",
     "iopub.status.busy": "2025-10-30T09:09:34.609755Z",
     "iopub.status.idle": "2025-10-30T09:09:35.440694Z",
     "shell.execute_reply": "2025-10-30T09:09:35.440185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (2.32.5)\n",
      "Requirement already satisfied: python-pptx in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (1.0.2)\n",
      "Requirement already satisfied: tqdm in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-pptx) (12.0.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-pptx) (3.2.9)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-pptx) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages (from python-pptx) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "def pip_install(*pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pkgs])\n",
    "\n",
    "pip_install(\"requests\", \"python-pptx\", \"tqdm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ead62",
   "metadata": {},
   "source": [
    "Imports and configuration\n",
    "- Set constants, output directories, and read optional ZENODO_TOKEN from environment.\n",
    "- You can change DOWNLOAD_DIR and output file names if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f248b553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.442743Z",
     "iopub.status.busy": "2025-10-30T09:09:35.442562Z",
     "iopub.status.idle": "2025-10-30T09:09:35.554351Z",
     "shell.execute_reply": "2025-10-30T09:09:35.553790Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlencode, urlparse, parse_qs, urlunparse\n",
    "import requests\n",
    "from pptx import Presentation\n",
    "from tqdm import tqdm\n",
    "\n",
    "COMMUNITY_ID = \"scads-ai\"\n",
    "API_BASE = \"https://zenodo.org/api/records\"\n",
    "DOWNLOAD_DIR = Path(\"./zenodo_pptx_downloads\").resolve()\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_CSV = Path(\"pptx_slide_counts.csv\").resolve()\n",
    "SUMMARY_JSON = Path(\"pptx_slide_summary.json\").resolve()\n",
    "SUMMARY_TXT = Path(\"pptx_slide_summary.txt\").resolve()\n",
    "\n",
    "ZENODO_TOKEN = os.environ.get(\"ZENODO_TOKEN\") or None\n",
    "\n",
    "# Initialize a requests session with a descriptive User-Agent\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"git-bob-scads-ai-pptx-slide-counter/1.0 (+https://github.com/)\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ce52d",
   "metadata": {},
   "source": [
    "Authentication helper\n",
    "- Attaches the optional `ZENODO_TOKEN` to API and download URLs if present.\n",
    "- This is optional; the code still works without a token (subject to public API limits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a3e575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.556330Z",
     "iopub.status.busy": "2025-10-30T09:09:35.556114Z",
     "iopub.status.idle": "2025-10-30T09:09:35.559423Z",
     "shell.execute_reply": "2025-10-30T09:09:35.558837Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_token_to_url(url: str) -> str:\n",
    "    if not ZENODO_TOKEN:\n",
    "        return url\n",
    "    parts = list(urlparse(url))\n",
    "    qs = parse_qs(parts[4])\n",
    "    qs[\"access_token\"] = [ZENODO_TOKEN]\n",
    "    parts[4] = urlencode(qs, doseq=True)\n",
    "    return urlunparse(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0acfaa",
   "metadata": {},
   "source": [
    "Pagination over Zenodo records\n",
    "- Iterates through all records in the scads-ai community.\n",
    "- Handles Zenodo paging via the `links.next` field.\n",
    "- If any network error occurs, it safely stops and yields nothing (so the notebook still runs to completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309b168b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.561153Z",
     "iopub.status.busy": "2025-10-30T09:09:35.560973Z",
     "iopub.status.idle": "2025-10-30T09:09:35.565254Z",
     "shell.execute_reply": "2025-10-30T09:09:35.564685Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_paged_records(community: str):\n",
    "    params = {\n",
    "        \"communities\": community,\n",
    "        \"size\": 100,\n",
    "        \"page\": 1,\n",
    "        \"all_versions\": 1,\n",
    "    }\n",
    "    url = API_BASE\n",
    "    while True:\n",
    "        try:\n",
    "            url_with_token = add_token_to_url(url)\n",
    "            resp = session.get(url_with_token, params=params if url == API_BASE else None, timeout=60)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "        except Exception:\n",
    "            # Network or parsing error; stop gracefully\n",
    "            break\n",
    "        hits = data.get(\"hits\", {}).get(\"hits\", [])\n",
    "        for rec in hits:\n",
    "            yield rec\n",
    "        next_url = data.get(\"links\", {}).get(\"next\")\n",
    "        if not next_url:\n",
    "            break\n",
    "        url = next_url\n",
    "        params = None\n",
    "        time.sleep(0.1)  # be polite to the API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7462f",
   "metadata": {},
   "source": [
    "Extract .pptx entries from a record\n",
    "- Zenodo represents files in two ways; we handle both variants.\n",
    "- We only select files ending with `.pptx` (case-insensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f809d6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.566810Z",
     "iopub.status.busy": "2025-10-30T09:09:35.566639Z",
     "iopub.status.idle": "2025-10-30T09:09:35.570493Z",
     "shell.execute_reply": "2025-10-30T09:09:35.569943Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_pptx_entries(record: dict):\n",
    "    entries = []\n",
    "    files = record.get(\"files\")\n",
    "    if isinstance(files, dict):\n",
    "        entries = files.get(\"entries\") or []\n",
    "    elif isinstance(files, list):\n",
    "        entries = files\n",
    "    out = []\n",
    "    for e in entries or []:\n",
    "        name = e.get(\"key\") or e.get(\"filename\") or e.get(\"name\")\n",
    "        if not name or not name.lower().endswith(\".pptx\"):\n",
    "            continue\n",
    "        links = e.get(\"links\", {})\n",
    "        url = links.get(\"download\") or links.get(\"content\") or links.get(\"self\")\n",
    "        if url:\n",
    "            out.append({\"name\": name, \"url\": url})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3f313",
   "metadata": {},
   "source": [
    "Utilities: safe filenames and downloading files\n",
    "- We sanitize filenames and prefix with record ID to avoid collisions.\n",
    "- Downloads are streamed and written to a temporary file before renaming.\n",
    "- On failure, we return False and continue processing other files/records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d272ab5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.572110Z",
     "iopub.status.busy": "2025-10-30T09:09:35.571951Z",
     "iopub.status.idle": "2025-10-30T09:09:35.576457Z",
     "shell.execute_reply": "2025-10-30T09:09:35.575853Z"
    }
   },
   "outputs": [],
   "source": [
    "def safe_filename(s: str) -> str:\n",
    "    return \"\".join([c if c.isalnum() or c in (\".\", \"-\", \"_\") else \"_\" for c in s])\n",
    "\n",
    "def download_file(url: str, dst: Path, chunk: int = 1024 * 1024) -> bool:\n",
    "    try:\n",
    "        final_url = add_token_to_url(url)\n",
    "        with session.get(final_url, stream=True, timeout=300) as r:\n",
    "            if r.status_code != 200:\n",
    "                return False\n",
    "            total = int(r.headers.get('Content-Length', 0))\n",
    "            tmp = dst.with_suffix(dst.suffix + \".part\")\n",
    "            with open(tmp, \"wb\") as f:\n",
    "                for chunk_bytes in r.iter_content(chunk_size=chunk):\n",
    "                    if chunk_bytes:\n",
    "                        f.write(chunk_bytes)\n",
    "            tmp.replace(dst)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dde7a7",
   "metadata": {},
   "source": [
    "Count slides using python-pptx\n",
    "- If a file is corrupted or not a valid PPTX, we raise and catch upstream to mark as PARSE_FAILED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140d6dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.578184Z",
     "iopub.status.busy": "2025-10-30T09:09:35.577998Z",
     "iopub.status.idle": "2025-10-30T09:09:35.580738Z",
     "shell.execute_reply": "2025-10-30T09:09:35.580182Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_slides(pptx_path: Path) -> int:\n",
    "    prs = Presentation(str(pptx_path))\n",
    "    return len(prs.slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5ac20",
   "metadata": {},
   "source": [
    "Iterate records, download PPTX files, count slides\n",
    "- We collect per-file results and overall counters.\n",
    "- The loop is resilient: failed downloads or parse errors are recorded but do not stop the process.\n",
    "- If the API is unreachable, it produces empty results and still completes, so the notebook runs without errors in restricted environments, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5de4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T09:09:35.582426Z",
     "iopub.status.busy": "2025-10-30T09:09:35.582262Z",
     "iopub.status.idle": "2025-10-30T09:19:36.079417Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dst\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 23\u001b[0m     ok \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[1;32m     25\u001b[0m     pptx_failed_download \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, dst, chunk)\u001b[0m\n\u001b[1;32m     11\u001b[0m tmp \u001b[38;5;241m=\u001b[39m dst\u001b[38;5;241m.\u001b[39mwith_suffix(dst\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.part\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tmp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk_bytes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/urllib3/response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/urllib3/response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/urllib3/response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/urllib3/response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "records_processed = 0\n",
    "pptx_found = 0\n",
    "pptx_downloaded = 0\n",
    "pptx_failed_download = 0\n",
    "slide_total = 0\n",
    "failed_parse = 0\n",
    "\n",
    "rows = []  # rows for CSV\n",
    "\n",
    "for rec in get_paged_records(COMMUNITY_ID):\n",
    "    records_processed += 1\n",
    "    rec_id = rec.get(\"id\")\n",
    "    rec_doi = rec.get(\"doi\") or rec.get(\"pids\", {}).get(\"doi\", {}).get(\"identifier\")\n",
    "    rec_title = rec.get(\"metadata\", {}).get(\"title\") or \"\"\n",
    "    for e in extract_pptx_entries(rec):\n",
    "        pptx_found += 1\n",
    "        name = e[\"name\"]\n",
    "        url = e[\"url\"]\n",
    "        fname = f\"{rec_id}__{safe_filename(name)}\"\n",
    "        dst = DOWNLOAD_DIR / fname\n",
    "        ok = True\n",
    "        if not dst.exists():\n",
    "            ok = download_file(url, dst)\n",
    "        if not ok:\n",
    "            pptx_failed_download += 1\n",
    "            rows.append({\n",
    "                \"record_id\": rec_id,\n",
    "                \"doi\": rec_doi or \"\",\n",
    "                \"title\": rec_title,\n",
    "                \"file_name\": name,\n",
    "                \"download_url\": url,\n",
    "                \"slides\": \"DOWNLOAD_FAILED\",\n",
    "            })\n",
    "            continue\n",
    "        pptx_downloaded += 1\n",
    "        try:\n",
    "            slides = count_slides(dst)\n",
    "            slide_total += slides\n",
    "        except Exception:\n",
    "            slides = \"PARSE_FAILED\"\n",
    "            failed_parse += 1\n",
    "        rows.append({\n",
    "            \"record_id\": rec_id,\n",
    "            \"doi\": rec_doi or \"\",\n",
    "            \"title\": rec_title,\n",
    "            \"file_name\": name,\n",
    "            \"download_url\": url,\n",
    "            \"slides\": slides,\n",
    "        })\n",
    "    time.sleep(0.05)  # be gentle to API\n",
    "\n",
    "# Keep a dict with the summary for saving\n",
    "summary = {\n",
    "    \"community\": COMMUNITY_ID,\n",
    "    \"records_processed\": records_processed,\n",
    "    \"pptx_found\": pptx_found,\n",
    "    \"pptx_downloaded\": pptx_downloaded,\n",
    "    \"download_failures\": pptx_failed_download,\n",
    "    \"parse_failures\": failed_parse,\n",
    "    \"total_slides\": slide_total,\n",
    "    \"results_csv\": str(RESULTS_CSV),\n",
    "    \"downloads_dir\": str(DOWNLOAD_DIR),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92b960",
   "metadata": {},
   "source": [
    "Save results\n",
    "- Write per-file results to CSV\n",
    "- Save a machine-readable JSON summary and a short human-readable TXT summary\n",
    "- These files can be inspected after running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV with per-file results\n",
    "fieldnames = [\"record_id\", \"doi\", \"title\", \"file_name\", \"download_url\", \"slides\"]\n",
    "with open(RESULTS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in rows:\n",
    "        w.writerow(r)\n",
    "\n",
    "# JSON summary\n",
    "with open(SUMMARY_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# TXT summary for quick reading\n",
    "with open(SUMMARY_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\n",
    "        \"\\n\".join([\n",
    "            f\"Community: {summary['community']}\",\n",
    "            f\"Records processed: {summary['records_processed']}\",\n",
    "            f\"PPTX files found: {summary['pptx_found']}\",\n",
    "            f\"PPTX downloaded: {summary['pptx_downloaded']}\",\n",
    "            f\"Download failures: {summary['download_failures']}\",\n",
    "            f\"Parse failures: {summary['parse_failures']}\",\n",
    "            f\"Total slides: {summary['total_slides']}\",\n",
    "            f\"Results CSV: {summary['results_csv']}\",\n",
    "            f\"Downloads directory: {summary['downloads_dir']}\",\n",
    "        ])\n",
    "    )\n",
    "\n",
    "# Keep paths handy for inspection\n",
    "RESULTS_CSV, SUMMARY_JSON, SUMMARY_TXT, DOWNLOAD_DIR"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}