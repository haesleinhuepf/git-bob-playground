{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2a9583",
   "metadata": {},
   "source": [
    "Symbol dynamics predictor\n",
    "\n",
    "This notebook learns a deterministic rule from the challenge API using:\n",
    "- Period detection for shape and color (KMP minimal period)\n",
    "- Variable-order Markov (context) model as fallback\n",
    "\n",
    "It minimizes API calls by caching past observations/predictions in a local log and only observing when needed. All intermediate steps are small and inspectable, and results are saved to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b2d5f",
   "metadata": {},
   "source": [
    "Install requirements. This ensures the notebook runs in clean environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b59e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:57.329996Z",
     "iopub.status.busy": "2025-10-11T21:49:57.329822Z",
     "iopub.status.idle": "2025-10-11T21:49:58.193629Z",
     "shell.execute_reply": "2025-10-11T21:49:58.193011Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "def pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n",
    "pip_install([\"requests\", \"pandas\", \"matplotlib\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7cdb9f",
   "metadata": {},
   "source": [
    "Configuration: API base URL, token, and log/output file paths. The base URL and token are provided by the organizers. Update if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b20a382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.195752Z",
     "iopub.status.busy": "2025-10-11T21:49:58.195534Z",
     "iopub.status.idle": "2025-10-11T21:49:58.477910Z",
     "shell.execute_reply": "2025-10-11T21:49:58.477383Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, json, time, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "BASE_URL = \"https://challenge.gcp.katana-labs.com\"\n",
    "TOKEN = \"f7ce2595765d1d3ce463a3825ddd67e3616bbe4bbe812fde17957d8fab7eb1f2\"\n",
    "\n",
    "LOG_JSONL = \"symbol_dynamics_log.jsonl\"\n",
    "PRED_CSV = \"predictions_log.csv\"\n",
    "STATS_CSV = \"symbol_stats.csv\"\n",
    "STATS_PNG = \"symbol_stats.png\"\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"Content-Type\": \"application/json\"})\n",
    "TIMEOUT = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee75a5",
   "metadata": {},
   "source": [
    "Symbol utilities: define the 9-symbol vocabulary and helpers for encoding/decoding, and for splitting shape/color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770ba64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.480016Z",
     "iopub.status.busy": "2025-10-11T21:49:58.479778Z",
     "iopub.status.idle": "2025-10-11T21:49:58.484663Z",
     "shell.execute_reply": "2025-10-11T21:49:58.484167Z"
    }
   },
   "outputs": [],
   "source": [
    "shapes = [\"circle\", \"triangle\", \"square\"]\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "all_symbols = [f\"{s}_{c}\" for s in shapes for c in colors]\n",
    "symbol_to_id = {s: i for i, s in enumerate(all_symbols)}\n",
    "id_to_symbol = {i: s for s, i in symbol_to_id.items()}\n",
    "\n",
    "def split_symbol(sym: str) -> Tuple[str, str]:\n",
    "    s, c = sym.split(\"_\")\n",
    "    return s, c\n",
    "\n",
    "def shape_id(sym: str) -> int:\n",
    "    s, _ = split_symbol(sym)\n",
    "    return shapes.index(s)\n",
    "\n",
    "def color_id(sym: str) -> int:\n",
    "    _, c = split_symbol(sym)\n",
    "    return colors.index(c)\n",
    "\n",
    "def encode_symbol(sym: str) -> int:\n",
    "    return symbol_to_id[sym]\n",
    "\n",
    "def decode_symbol(idx: int) -> str:\n",
    "    return id_to_symbol[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c18a2",
   "metadata": {},
   "source": [
    "Minimal period estimation using the KMP prefix function. This works for incomplete periods too (no need that the sample length is a multiple of the period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe02070c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.486301Z",
     "iopub.status.busy": "2025-10-11T21:49:58.486137Z",
     "iopub.status.idle": "2025-10-11T21:49:58.495301Z",
     "shell.execute_reply": "2025-10-11T21:49:58.494822Z"
    }
   },
   "outputs": [],
   "source": [
    "def kmp_prefix_function(arr: List[int]) -> List[int]:\n",
    "    pi = [0] * len(arr)\n",
    "    for i in range(1, len(arr)):\n",
    "        j = pi[i-1]\n",
    "        while j > 0 and arr[i] != arr[j]:\n",
    "            j = pi[j-1]\n",
    "        if arr[i] == arr[j]:\n",
    "            j += 1\n",
    "        pi[i] = j\n",
    "    return pi\n",
    "\n",
    "def minimal_period_prefix(arr: List[int]) -> Optional[int]:\n",
    "    if len(arr) < 2:\n",
    "        return None\n",
    "    pi = kmp_prefix_function(arr)\n",
    "    p = len(arr) - pi[-1]\n",
    "    if p < len(arr):\n",
    "        # verify the candidate period p covers all positions\n",
    "        for i in range(p, len(arr)):\n",
    "            if arr[i] != arr[i - p]:\n",
    "                return None\n",
    "        return p\n",
    "    return None\n",
    "\n",
    "@dataclass\n",
    "class PeriodModel:\n",
    "    shape_period: Optional[int]\n",
    "    color_period: Optional[int]\n",
    "    shape_pattern: Optional[List[int]]\n",
    "    color_pattern: Optional[List[int]]\n",
    "\n",
    "    def predict(self, t: int) -> Optional[str]:\n",
    "        if self.shape_period is None or self.color_period is None:\n",
    "            return None\n",
    "        s = shapes[self.shape_pattern[t % self.shape_period]]\n",
    "        c = colors[self.color_pattern[t % self.color_period]]\n",
    "        return f\"{s}_{c}\"\n",
    "\n",
    "def fit_period_model(symbols: List[str]) -> PeriodModel:\n",
    "    shp = [shape_id(s) for s in symbols]\n",
    "    col = [color_id(s) for s in symbols]\n",
    "    sp = minimal_period_prefix(shp)\n",
    "    cp = minimal_period_prefix(col)\n",
    "    shape_pattern = shp[:sp] if sp else None\n",
    "    color_pattern = col[:cp] if cp else None\n",
    "    return PeriodModel(sp, cp, shape_pattern, color_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85658af5",
   "metadata": {},
   "source": [
    "Variable-order context model (n-gram with backoff). Keeps small deterministic next-symbol maps, using majority when not unique. This is a compact fallback if there is a finite-order rule not captured by pure periodicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "909e134f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.496909Z",
     "iopub.status.busy": "2025-10-11T21:49:58.496734Z",
     "iopub.status.idle": "2025-10-11T21:49:58.503235Z",
     "shell.execute_reply": "2025-10-11T21:49:58.502795Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextModel:\n",
    "    def __init__(self, max_order: int = 30):\n",
    "        self.max_order = max_order\n",
    "        self.counts: List[Dict[Tuple[int, ...], Counter]] = [defaultdict(Counter) for _ in range(self.max_order+1)]\n",
    "        self.det_next: List[Dict[Tuple[int, ...], int]] = [dict() for _ in range(self.max_order+1)]\n",
    "\n",
    "    def fit(self, seq: List[int]):\n",
    "        self.counts = [defaultdict(Counter) for _ in range(self.max_order+1)]\n",
    "        self.det_next = [dict() for _ in range(self.max_order+1)]\n",
    "        n = len(seq)\n",
    "        for i in range(n-1):\n",
    "            up = min(self.max_order, i+1)\n",
    "            for k in range(1, up+1):\n",
    "                ctx = tuple(seq[i-k+1:i+1])\n",
    "                nxt = seq[i+1]\n",
    "                self.counts[k][ctx][nxt] += 1\n",
    "        self._refresh()\n",
    "\n",
    "    def _refresh(self):\n",
    "        for k in range(1, self.max_order+1):\n",
    "            d = {}\n",
    "            for ctx, cnt in self.counts[k].items():\n",
    "                d[ctx] = cnt.most_common(1)[0][0]\n",
    "            self.det_next[k] = d\n",
    "\n",
    "    def predict_next_id(self, history_ids: List[int]) -> Optional[int]:\n",
    "        L = min(self.max_order, len(history_ids))\n",
    "        for k in range(L, 0, -1):\n",
    "            ctx = tuple(history_ids[-k:])\n",
    "            nxt = self.det_next[k].get(ctx)\n",
    "            if nxt is not None:\n",
    "                return nxt\n",
    "        return None\n",
    "\n",
    "def fit_models(observed_symbols: List[str], max_order: int = 30) -> Tuple[PeriodModel, ContextModel]:\n",
    "    period_model = fit_period_model(observed_symbols)\n",
    "    ctx = ContextModel(max_order=max_order)\n",
    "    ctx.fit([encode_symbol(s) for s in observed_symbols])\n",
    "    return period_model, ctx\n",
    "\n",
    "def period_available(pm: PeriodModel) -> bool:\n",
    "    return pm.shape_period is not None and pm.color_period is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc784599",
   "metadata": {},
   "source": [
    "Logging helpers: we store every API interaction in a JSONL file. We also provide utilities to load the log and reconstruct observed and virtual histories, plus the latest server position. This minimizes re-observation across runs and API calls overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a23a75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.504827Z",
     "iopub.status.busy": "2025-10-11T21:49:58.504636Z",
     "iopub.status.idle": "2025-10-11T21:49:58.512532Z",
     "shell.execute_reply": "2025-10-11T21:49:58.512072Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_log(entry: Dict):\n",
    "    entry = dict(entry)\n",
    "    entry[\"ts\"] = dt.datetime.utcnow().isoformat() + \"Z\"\n",
    "    with open(LOG_JSONL, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "def load_log() -> List[Dict]:\n",
    "    if not os.path.exists(LOG_JSONL):\n",
    "        return []\n",
    "    entries = []\n",
    "    with open(LOG_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                entries.append(json.loads(line))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return entries\n",
    "\n",
    "def reconstruct_histories(entries: List[Dict]) -> Tuple[List[str], List[str], int]:\n",
    "    observed_history: List[str] = []\n",
    "    virtual_history: List[str] = []\n",
    "    latest_pos = 0\n",
    "    for e in entries:\n",
    "        latest_pos = e.get(\"position\", latest_pos)\n",
    "        if e.get(\"type\") == \"observe\":\n",
    "            syms = e.get(\"symbols\", [])\n",
    "            observed_history.extend(syms)\n",
    "            virtual_history.extend(syms)\n",
    "        elif e.get(\"type\") == \"predict\":\n",
    "            preds = e.get(\"predictions\", [])\n",
    "            # Extend virtual history with our past predictions to keep time indexing consistent\n",
    "            virtual_history.extend(preds)\n",
    "    return observed_history, virtual_history, latest_pos\n",
    "\n",
    "def ensure_pred_csv_header():\n",
    "    if not os.path.exists(PRED_CSV):\n",
    "        pd.DataFrame(columns=[\"timestamp\",\"position\",\"streak\",\"correct\",\"predictions\"]).to_csv(PRED_CSV, index=False)\n",
    "\n",
    "ensure_pred_csv_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c06ef1",
   "metadata": {},
   "source": [
    "API wrappers: small helpers to call /observe and /predict, with logging to disk and minimal overhead. We always trust the server-reported position to stay in sync across sessions/runs. We append all responses to the JSONL log for future reuse and minimal calls later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eade858a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.514085Z",
     "iopub.status.busy": "2025-10-11T21:49:58.513921Z",
     "iopub.status.idle": "2025-10-11T21:49:58.518823Z",
     "shell.execute_reply": "2025-10-11T21:49:58.518367Z"
    }
   },
   "outputs": [],
   "source": [
    "def _url(path: str) -> str:\n",
    "    return BASE_URL.rstrip(\"/\") + path\n",
    "\n",
    "def api_observe() -> Tuple[List[str], int]:\n",
    "    r = session.post(_url(\"/observe\"), json={\"token\": TOKEN}, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    syms = data.get(\"symbols\", [])\n",
    "    pos = data.get(\"position\", 0)\n",
    "    append_log({\"type\": \"observe\", \"symbols\": syms, \"position\": pos})\n",
    "    return syms, pos\n",
    "\n",
    "def api_predict(preds: List[str]) -> Tuple[int, int, int]:\n",
    "    payload = {\"token\": TOKEN, \"predictions\": preds}\n",
    "    r = session.post(_url(\"/predict\"), json=payload, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    correct = int(data.get(\"correct\", 0))\n",
    "    streak = int(data.get(\"streak\", 0))\n",
    "    pos = int(data.get(\"position\", 0))\n",
    "    append_log({\"type\": \"predict\", \"predictions\": preds, \"correct\": correct, \"streak\": streak, \"position\": pos})\n",
    "    # CSV for quick tracking\n",
    "    row = {\"timestamp\": dt.datetime.utcnow().isoformat()+\"Z\", \"position\": pos, \"streak\": streak, \"correct\": correct, \"predictions\": json.dumps(preds)}\n",
    "    pd.DataFrame([row]).to_csv(PRED_CSV, mode=\"a\", header=False, index=False)\n",
    "    return correct, streak, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cf8f8",
   "metadata": {},
   "source": [
    "Load existing log and reconstruct histories. We reuse past observations to train models and past predictions to keep a virtual timeline, avoiding unnecessary observation calls. If the log is empty or too short, we will make a few observations next to bootstrap the models efficiently but minimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aed30dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:49:58.520321Z",
     "iopub.status.busy": "2025-10-11T21:49:58.520145Z",
     "iopub.status.idle": "2025-10-11T21:50:04.023598Z",
     "shell.execute_reply": "2025-10-11T21:50:04.022994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2486/169478932.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  entry[\"ts\"] = dt.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    }
   ],
   "source": [
    "entries = load_log()\n",
    "observed_history, virtual_history, current_pos = reconstruct_histories(entries)\n",
    "# Minimal bootstrap target (in symbols) if we have no data\n",
    "MIN_BOOTSTRAP = 60\n",
    "if len(observed_history) < MIN_BOOTSTRAP:\n",
    "    needed = (MIN_BOOTSTRAP - len(observed_history) + 9) // 10\n",
    "    for _ in range(needed):\n",
    "        syms, current_pos = api_observe()\n",
    "        observed_history.extend(syms)\n",
    "        virtual_history.extend(syms)\n",
    "    # Refresh entries if needed later\n",
    "    entries = load_log()\n",
    "    observed_history, virtual_history, current_pos = reconstruct_histories(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349fe39",
   "metadata": {},
   "source": [
    "Fit the period model and the context model. Both are retrained from observed history only to avoid compounding errors from unconfirmed predictions. The period model can predict using absolute position t, while the context model uses recent history as fallback when periodicity is not fully detected or is too long to capture from bootstrap data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28542927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:50:04.025773Z",
     "iopub.status.busy": "2025-10-11T21:50:04.025577Z",
     "iopub.status.idle": "2025-10-11T21:50:04.032995Z",
     "shell.execute_reply": "2025-10-11T21:50:04.032524Z"
    }
   },
   "outputs": [],
   "source": [
    "period_model, context_model = fit_models(observed_history, max_order=30)\n",
    "periodic = period_available(period_model)\n",
    "period_info = {\n",
    "    \"shape_period\": period_model.shape_period,\n",
    "    \"color_period\": period_model.color_period,\n",
    "    \"periodic\": periodic\n",
    "}\n",
    "with open(\"period_model_info.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(period_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d7453",
   "metadata": {},
   "source": [
    "Save quick statistics about observed data for inspection: counts and a simple plot. This helps verify we are seeing structured data and stores artifacts for later review without re-running the API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6190668e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:50:04.034501Z",
     "iopub.status.busy": "2025-10-11T21:50:04.034340Z",
     "iopub.status.idle": "2025-10-11T21:50:06.131095Z",
     "shell.execute_reply": "2025-10-11T21:50:06.130492Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sym_counts = Counter(observed_history)\n",
    "df_counts = pd.DataFrame({\"symbol\": list(sym_counts.keys()), \"count\": list(sym_counts.values())}).sort_values(\"symbol\")\n",
    "df_counts.to_csv(STATS_CSV, index=False)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.bar(df_counts[\"symbol\"], df_counts[\"count\"], color=\"steelblue\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(STATS_PNG, dpi=150)\n",
    "plt.close()  # ensure no inline display remains after saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73827dd8",
   "metadata": {},
   "source": [
    "Batch prediction function: combine periodic predictor (if available) with context fallback. We use a virtual history for roll-out across predictions to provide context, while periodic prediction uses absolute positions (server positions) for accuracy when the process is periodic. Virtual history is updated with predicted symbols to maintain continuity across rounds without extra API calls. We only observe again if streak falls below a threshold to re-sync/update models minimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9d3dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:50:06.133158Z",
     "iopub.status.busy": "2025-10-11T21:50:06.132972Z",
     "iopub.status.idle": "2025-10-11T21:50:06.137144Z",
     "shell.execute_reply": "2025-10-11T21:50:06.136710Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_symbol_at(t_abs: int, virt_hist: List[str]) -> str:\n",
    "    if period_available(period_model):\n",
    "        ps = period_model.predict(t_abs)\n",
    "        if ps is not None:\n",
    "            return ps\n",
    "    # context fallback\n",
    "    hid = [encode_symbol(s) for s in virt_hist]\n",
    "    nxt_id = context_model.predict_next_id(hid)\n",
    "    if nxt_id is not None:\n",
    "        return decode_symbol(nxt_id)\n",
    "    # global frequency fallback\n",
    "    if virt_hist:\n",
    "        mc = Counter(virt_hist).most_common(1)[0][0]\n",
    "        return mc\n",
    "    return \"circle_red\"\n",
    "\n",
    "def predict_batch(start_t_abs: int, virt_hist: List[str], n: int = 10) -> List[str]:\n",
    "    preds = []\n",
    "    for i in range(n):\n",
    "        sym = predict_symbol_at(start_t_abs + i, virt_hist)\n",
    "        preds.append(sym)\n",
    "        virt_hist.append(sym)  # teacher-forcing rollout\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65448c12",
   "metadata": {},
   "source": [
    "Play loop with minimal calls: we predict a few batches and only observe if our streak drops below a threshold. All interactions are logged to disk. You can re-run this cell later to continue from the same state without re-observing, thanks to the log reuse. Adjust rounds and thresholds if desired.\n",
    "\n",
    "Note: If the process is periodic in both shape and color, predictions should achieve perfect streaks after a short bootstrap, making extra observations unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a908427a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T21:50:06.138790Z",
     "iopub.status.busy": "2025-10-11T21:50:06.138593Z",
     "iopub.status.idle": "2025-10-11T21:50:15.273434Z",
     "shell.execute_reply": "2025-10-11T21:50:15.272886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2486/169478932.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  entry[\"ts\"] = dt.datetime.utcnow().isoformat() + \"Z\"\n",
      "/tmp/ipykernel_2486/3957781886.py:23: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  row = {\"timestamp\": dt.datetime.utcnow().isoformat()+\"Z\", \"position\": pos, \"streak\": streak, \"correct\": correct, \"predictions\": json.dumps(preds)}\n"
     ]
    }
   ],
   "source": [
    "# Parameters for minimal-call prediction loop\n",
    "ROUNDS = 5\n",
    "OBSERVE_ON_LOW_STREAK = True\n",
    "LOW_STREAK_THRESHOLD = 6\n",
    "\n",
    "# Ensure virtual history is aligned with last known server position\n",
    "entries = load_log()\n",
    "observed_history, virtual_history, current_pos = reconstruct_histories(entries)\n",
    "\n",
    "for r in range(ROUNDS):\n",
    "    preds = predict_batch(start_t_abs=current_pos, virt_hist=virtual_history, n=10)\n",
    "    correct, streak, current_pos = api_predict(preds)\n",
    "    # Optionally observe to re-sync/update models if performance drops\n",
    "    if OBSERVE_ON_LOW_STREAK and streak < LOW_STREAK_THRESHOLD:\n",
    "        syms, current_pos = api_observe()\n",
    "        observed_history.extend(syms)\n",
    "        # Update models with new ground-truth observations only\n",
    "        period_model, context_model = fit_models(observed_history, max_order=30)\n",
    "        periodic = period_available(period_model)\n",
    "        # keep virtual history consistent with time: extend with observed true symbols as well\n",
    "        virtual_history.extend(syms)\n",
    "    # Save brief round summary alongside JSONL/CSV (already appended)\n",
    "    with open(\"last_run_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"round={r+1}, streak={streak}, correct={correct}, position={current_pos}, periodic={periodic}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
