{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c31548",
   "metadata": {},
   "source": [
    "# Activation Functions Plots\n",
    "\n",
    "This notebook demonstrates three common activation functions: Linear, Sigmoid, and ReLU. We will plot each function and save them as .png files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551096a9",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "We will use `numpy` for numerical operations and `matplotlib` for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bba965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:18.158895Z",
     "iopub.status.busy": "2024-10-29T13:30:18.158895Z",
     "iopub.status.idle": "2024-10-29T13:30:18.879203Z",
     "shell.execute_reply": "2024-10-29T13:30:18.878358Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81c27d",
   "metadata": {},
   "source": [
    "## Define the Linear Activation Function\n",
    "\n",
    "Linear activation function is simply the identity function, which is often represented as `f(x) = x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78b0f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:18.881730Z",
     "iopub.status.busy": "2024-10-29T13:30:18.880731Z",
     "iopub.status.idle": "2024-10-29T13:30:18.883791Z",
     "shell.execute_reply": "2024-10-29T13:30:18.883791Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677cadf",
   "metadata": {},
   "source": [
    "## Plot the Linear Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29882952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:18.884795Z",
     "iopub.status.busy": "2024-10-29T13:30:18.884795Z",
     "iopub.status.idle": "2024-10-29T13:30:19.011391Z",
     "shell.execute_reply": "2024-10-29T13:30:19.010877Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "y_linear = linear(x)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x, y_linear, label='Linear')\n",
    "plt.title('Linear Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('linear_activation.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dcbfc",
   "metadata": {},
   "source": [
    "## Define the Sigmoid Activation Function\n",
    "\n",
    "The Sigmoid activation function is defined as `f(x) = 1 / (1 + exp(-x))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc8d412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:19.013344Z",
     "iopub.status.busy": "2024-10-29T13:30:19.013344Z",
     "iopub.status.idle": "2024-10-29T13:30:19.016375Z",
     "shell.execute_reply": "2024-10-29T13:30:19.016375Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f92a3",
   "metadata": {},
   "source": [
    "## Plot the Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe9e1f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:19.018497Z",
     "iopub.status.busy": "2024-10-29T13:30:19.017490Z",
     "iopub.status.idle": "2024-10-29T13:30:19.074158Z",
     "shell.execute_reply": "2024-10-29T13:30:19.073652Z"
    }
   },
   "outputs": [],
   "source": [
    "y_sigmoid = sigmoid(x)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x, y_sigmoid, label='Sigmoid', color='r')\n",
    "plt.title('Sigmoid Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('sigmoid_activation.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602cca3",
   "metadata": {},
   "source": [
    "## Define the ReLU Activation Function\n",
    "\n",
    "ReLU (Rectified Linear Unit) is defined as `f(x) = max(0, x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58c48c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:19.076164Z",
     "iopub.status.busy": "2024-10-29T13:30:19.076164Z",
     "iopub.status.idle": "2024-10-29T13:30:19.078598Z",
     "shell.execute_reply": "2024-10-29T13:30:19.078598Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a198f94",
   "metadata": {},
   "source": [
    "## Plot the ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00ac2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:30:19.079633Z",
     "iopub.status.busy": "2024-10-29T13:30:19.079633Z",
     "iopub.status.idle": "2024-10-29T13:30:19.139673Z",
     "shell.execute_reply": "2024-10-29T13:30:19.139673Z"
    }
   },
   "outputs": [],
   "source": [
    "y_relu = relu(x)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x, y_relu, label='ReLU', color='g')\n",
    "plt.title('ReLU Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('relu_activation.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
